---
apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: "backfill-configurator-{{ macros.uuid.uuid4() }}"
  namespace: dedp-ch03
spec:
  type: Scala
  mode: cluster
  image: "docker.io/library/dedp_ch03_backfilling_configurator:latest"
  imagePullPolicy: Never
  mainClass: com.waitingforcode.BackfillConfigurationCreationJob
  mainApplicationFile: "local:///tmp/backfilling_configurator-1.0-SNAPSHOT-jar-with-dependencies.jar"
  arguments:
    - '--outputLocation'
    - "/data_for_demo/"
    - '--tableFullPath'
    - "/data_for_demo/devices"
    - '--outputBackfillingFileName'
    - "{{ params.config_file_name }}"
    - '--currentPartition'
    - "event_time={{ ds }}"
  sparkVersion: "3.5.0"
  restartPolicy:
    type: Never
  volumes:
    - name: "datasets"
      hostPath:
        path: "/data_for_demo"
  driver:
    cores: 1
    coreLimit: "1200m"
    memory: "512m"
    labels:
      version: 3.5.0
    serviceAccount: spark-editor
    volumeMounts:
    - mountPath: "/data_for_demo"
      name: "datasets"
  executor:
    cores: 1
    instances: 1
    memory: "512m"
    labels:
      version: 3.5.0
    volumeMounts:
    - mountPath: "/data_for_demo"
      name: "datasets"