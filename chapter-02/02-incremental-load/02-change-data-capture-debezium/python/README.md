1. Generate the dataset and start the containers:
```
cd docker/
docker-compose down --volumes; docker-compose up
```
2. Register the Kafka Connect consumer that will stream PostgreSQL records to Apache Kafka:
```
cd docker/
curl -i -X POST -H "Accept:application/json" -H  "Content-Type:application/json" http://localhost:8083/connectors/ -d @register-postgresql-connector.json
``` 
3. Open the [visits_stream_processor.py](visits_stream_processor.py)
* it's a classical Structured Streaming consumer to process created (`filter('visit.payload.op = "c"')`) records
  and aggregate them to 30-seconds windows
4. Run the `visits_stream_processor.py`; you should see the windows printed in the console
5. Run Apache Kafka consumer to see the records generated by the Kafka Connect:
```
docker exec -ti docker_kafka_1 kafka-console-consumer.sh \
    --bootstrap-server kafka:9092 \
    --from-beginning \
    --property print.key=true \
    --topic dedp.dedp_schema.visits
```
